# jemdoc: menu{MENU}{projs.html}, nofooter
= Projects

== Natural Language Processing

In my time at Microsoft Research and at IIT Kanpur, I have had the chance to explore both practical and theoretical problems in machine learning \n \n
- *Text Categorization using Sparse Composite Vectors* \n In these project, I worked on novel topic-based document representation (distributional semantics representation) which outperforms state-of-the-art models in multi-class and multi-label classification tasks. We also showed that fuzzy GMM clustering on word-vectors lead to more coherent topic than LDA and can be used to detect Polysemic words. (Joint work with Dheeraj Mekala, IIT Kanpur, Bhargavi Paranjape, Microsoft Research Lab, India & Harish Karnick, IIT Kanpur)
- *Product Classification using Distributional Semantics* \n In this project, I worked on the problem of tackling heirarichal product classification for a given ontology(taxonomy) tree using a novel two-level ensemble approach utilizing (with respect to the taxonomy tree) a path-wise, node-wise and depth-wise classifiers for product classification.(Joint work with Harish Karnick, IIT Kanpur, Ashendra Bansal, Flikart.com & Pradhuman Jhala, Flipkart.com)
- *Text Summarization using Abstract Meaning Representation* \n In this project, we explored a full-fledged pipeline for text summarization with an intermediate step of Abstract Meaning Representation (AMR). Our proposed method achieves state-of the-art results compared to the other text summarization
routines based on AMR. (Joint work with Shibhansh Dohare, IIT Kanpur & Harish Karnick, IIT Kanpur)

== Machine Learning
- *Leveraging Distributional Semantics for Multi-Label Learning* \n In this project, I worked on the problem of designing embedding based multi-label learning algorithms using distributional semantics which has more efficient training procedures. We extended the approach to naturally incorporate other sources of side-information, in particular the label-label co-occurrence matrix. (Joint work with Rahul Wadbude, IIT Kanpur, Piyush Rai, IIT Kanpur, Nagararjan Natararjan, Microsoft Research Lab, India & Harish Karnick, IIT Kanpur)
- *Efficient Estimation of Generalization Error and Bias-Variance Components of Ensembles* \n In this project, I worked on the problem of efficient Estimation of generalization error for ensembles using normality assumption on classification scores. We worked on efficient prediction of accuracy, ensemble parameters, bias and variance of generalization errors using minimal number of ensembles. (Work done as part of summer internship under Sundararajan Sellamanickam)
- *Bayes Optimal Classication for Hierarchy* \n In this project, I worked on the problem of finding bayes optimal classifier for Hierarchical classfication for assymetric loss. Showed under reasonable assumption over hierarchy that the Bayes optimal classification for this asymmetric loss can be found in O(log(n)). Currently extending the consistency of hierarchical classification algorithm on asymmetric tree distance loss
using calibrated surrogates. (Joint work with Dheeraj Mekala, IIT Kanpur, Purushottam Kar, IIT Kanpur & Harish Karnick, IIT Kanpur)
